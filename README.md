# ðŸŒ‹ Visual Question-Answer-Distractors Generation

**Can We Learn Question, Answer, and Distractors All from An Image? A New Task for Multiple-Choice Visual Question Answering** [[Paper](https://aclanthology.org/2024.lrec-main.254.pdf)] <br>

## Release

- [2024/09/24] Codes are released.

- [2024/02/22] [VQADG](https://aclanthology.org/2024.lrec-main.254.pdf) is accepted by LREC-Coling 2024 as **poster presentation**


## Quick Start

```Shell
bash VQADG.sh # baseline model

bash VQADG_cts.sh # baseline model + contrastive learning
```

## Citation

If you find our paper is useful for your research and applications, please cite using this BibTeX:
```bibtex
@inproceedings{ding2024can,
  title={Can We Learn Question, Answer, and Distractors All from an Image? A New Task for Multiple-choice Visual Question Answering},
  author={Ding, Wenjian and Zhang, Yao and Wang, Jun and Jatowt, Adam and Yang, Zhenglu},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  pages={2852--2863},
  year={2024}
}